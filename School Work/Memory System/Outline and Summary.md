1. Address space, is the running program's view of memory in the system. When we describe theaddress space, what we are describing is the abstraction that the OS is providing to the running program. When the OS does this, we say the OS is **virtualizing memory**, because the running program thinks it is loaded into memory at a particular address (say 0) and has a potentially very large address space (say 32-bits or 64-bits); the reality is quite different.

2. The address space of a process contains all of the memory state of the running program. For example, the code, stack, and heap.

3. The *code* of the program (the instructions) have to live in memory somewhere, and thus they are in the address space. 

   The program, while it is running, uses a *stack* to keep track of where it is in the function call chain as well as to allocate local variables and pass parameters and return values to and from routines. 
   
   Finally, the *heap* is used for dynamically-allocated, user-managed memory, such as that you might receive from a call to malloc() in C or new in an object-oriented language such as C++ or Java
   
4. **Address translation**, is that the hardware takes a virtual address the process thinks it is referencing and transforms it into a physical address which is where the data actually resides.

5. A **base** register is used to transform virtualaddresses (generated by the program) into physical addresses. A **bounds**(or limit) register ensures that such addresses are within the confines of the address space.

6. Sometimes people call the part of the processor that helps with address translation the memory management unit (MMU). Each CPU had an additional pair of registers (**base and bounds registers**), part of the **MMU** of the CPU.

Notes: In both "Three easy pieces" and "Operating System Concepts", **BOUND/LIMIT** holds the *size* of the address space (and thus the hardware checks the virtual address against it first before adding the base) rather than the physical address of the end of the address space.

7. **Internal fragmentation and external fragmentation**(Distinguish these two concepts!!!)
8. Fixed-sized slot leads to internal fragmentation. To avoid this,**segmentation** is introduced.

9. A 32-bit address space means 4GB in size.

10. The idea of **segmentation**:
Instead of having just one base and bounds pair in our MMU, we can have a base and bounds pair per logical segment of the address space (e.g. In our cononical address space, we have 3 logically-different segments: code, stack, heap.). What segmentation allows the OS to do is to place each one of those segments in different parts of physical memory, and thus avoid filling physical memory with unused virtual address space. In this way, only used memory is allocated space in physical memory, and thus large address spaces with large amounts of unused address space (which we sometimes call sparse address spaces) can be accommodated.

11. The general problem that arises when applying segmentation is that physical memory quickly be- comes full of little holes of free space, making it difficult to allocate new segments, or to grow existing ones. We call this problem external fragmentation. One solution to this problem would be to compact physical memory by rearranging the existing segments.

12.A simpler approach is to use a free-list management algorithm that tries to keep large extents of memory available for allocation. There are literally hundreds of approaches that people have taken, including classic algorithms like **best-fit (which keeps a list of free spaces and returns the one closest in size that satisfies the desired allocation to the requester)**, **worst-fit**, **first-fit**, and more complex schemes like **buddy algorithm**.

13. However, segmentation can lead to external fragmentation.

14. Ways to overcome the problem of external fragmentation: smart algorithms (best-fit, worst-fit, first-fit, buddy system etc.) or periodic compaction

15.**External fragmentation**: the free space gets chopped into little pieces of different sizes and is thus fragmented; subsequent re- quests may fail because there is no single contiguous space that can sat- isfy the request, even though the total amount of free space exceeds the size of the request.

16. Basic strategies for managing free space:

**Best fit**:

The best fit strategy is quite simple: first, search through the free list and find chunks of free memory that are as big or bigger than the requested size. Then, return the one that is the smallest in that group of candidates.

Need to go through the whole list to find the right one.

The intuition behind best fit is simple: by returning a block that is close to what the user asks, best fit tries to reduce wasted space. However, there is a cost; naive implementations pay a heavy performance penalty when performing an exhaustive search for the correct free block.

**Worst fit**:

The worst fit approach is the opposite of best fit; find the largest chunk and return the requested amount.


**First fit**:
The first fit method simply finds the first block that is big enough and returns the requested amount to the user.

First fit has the advantage of speed — no exhaustive search of all the free spaces are necessary — but sometimes pollutes the beginning of the free list with small objects.

16. **Buddy System**

In such a system, free memory is first conceptually thought of as one big space of size 2N . When a request for memory is made, the search for free space recursively divides free space by two until a block that is big enough to accommodate the request is found (and a further split into two would result in a space that is too small).

When returning the 8KB block to the free list, the allocator checks whether the “buddy” 8KB is free; if so, it coalesces the two blocks into a 16KB block. The allocator then checks if the buddy of the 16KB block is still free; if so, it coalesces those two blocks. This recursive coa- lescing process continues up the tree, either restoring the entire free space or stopping when a buddy is found to be in use.

note that this scheme can suffer from internal fragmentation, as you are only allowed to give out power-of-two-sized blocks.

**Paging**: Instead of splitting up a process’s address space into some number of variable-sized logical segments (e.g., code, heap, stack), we divide it into fixed-sized units, each of which we call a page. Correspondingly, we view physical memory as an array of fixed-sized slots called page frames; **each of these frames can contain a single virtual-memory page.**

To record where each virtual page of the address space is placed in physical memory, the operating system usually keeps a per-process data structure known as a **page table**.

If *another process* were to run in our example above, the OS would have to manage a different page table for it, as its virtual pages obviously map to different physical pages.

A **TLB (translation-lookaside Buffer)** is part of the chip’s memory-management unit (MMU), and is simply a hardware cache of popular virtual-to-physical address translations

Upon each virtual memory reference, the hardware first checks the TLB to see if the desired translation is held therein; if so, the translation is performed (quickly) without having to consult the page table (which has all translations).
